{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXzkQhiO5L3W"
      },
      "outputs": [],
      "source": [
        "!pip install ffmpeg-python\n",
        "!pip install pyannote.audio\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Google authentication\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# File download from Google Drive\n",
        "file_id = '1J0LWDdCjUzDQVyEHQ6b_j41baKV4exEu'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('downloaded_video.mp4')"
      ],
      "metadata": {
        "id": "fIcInKoU5f8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ffmpeg\n",
        "import os\n",
        "\n",
        "input_video = 'downloaded_video.mp4'\n",
        "output_audio = 'extracted_audio.wav'\n",
        "\n",
        "# # If there is the file exists, then ffmpeg error will occur... remove the file\n",
        "# os.remove(output_audio)\n",
        "\n",
        "ffmpeg.input(input_video).output(output_audio).run()"
      ],
      "metadata": {
        "id": "iEU2DeDm524k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pyannote.audio import Pipeline\n",
        "# import torch\n",
        "\n",
        "# # If you want to this code, then you should agree pyannote agreement...\n",
        "# # Check this URL: https://huggingface.co/pyannote/speaker-diarization\n",
        "# # But this code takes much time, so I don't use them.\n",
        "# pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\",\n",
        "#                                     use_auth_token='USE_YOUR_HUGGING_FACE_TOKEN')\n",
        "\n",
        "# pipeline.to(torch.device(\"cuda\"))\n",
        "\n",
        "# # Apply pretrained pipeline\n",
        "# diarization = pipeline(\"extracted_audio.wav\")\n",
        "\n",
        "# for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
        "#     print(f\"Speaker {speaker} says from {turn.start:.1f}sec to {turn.end:.1f}sec\")"
      ],
      "metadata": {
        "id": "blvwjXRj5_23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# You can use the model \"large\", but the code need more time\n",
        "model = whisper.load_model(\"medium\")\n",
        "result = model.transcribe(output_audio)\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "id": "3gdqyhTs9lKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_paragraphs(text, max_tokens=1024):\n",
        "    sentences = text.split('.')\n",
        "    paragraphs = []\n",
        "    current_paragraph = \"\"\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.strip() + '.'\n",
        "\n",
        "        if len((current_paragraph + \" \" + sentence).split()) > max_tokens:\n",
        "            paragraphs.append(current_paragraph.strip())\n",
        "            current_paragraph = sentence\n",
        "        else:\n",
        "            current_paragraph += \" \" + sentence\n",
        "\n",
        "    if current_paragraph:\n",
        "        paragraphs.append(current_paragraph.strip())\n",
        "\n",
        "    return paragraphs"
      ],
      "metadata": {
        "id": "MDo_L6djrnX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model='facebook/bart-large-cnn')\n",
        "paragraphs = create_paragraphs(result['text'], 512)\n",
        "\n",
        "summaries = []\n",
        "\n",
        "for i, paragraph in enumerate(paragraphs):\n",
        "   summary = summarizer(paragraph, max_length=150, min_length=30, do_sample=False)[0]['summary_text']\n",
        "   summaries.append((paragraph, summary))\n",
        "\n",
        "   print(f'# paragraph {i}')\n",
        "   print('Summary:', summary)\n",
        "   print('Body:', paragraph)\n",
        "   print()"
      ],
      "metadata": {
        "id": "k7LrP-0m6vzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tAapH6IO4Dim"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}